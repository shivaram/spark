#!/usr/bin/env bash

#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#


# Figure out where the Spark framework is installed
FWDIR="$(cd `dirname $0`; cd ../; pwd)"

FAILED=0

$FWDIR/pyspark pyspark/rdd.py
FAILED=$(($?||$FAILED))

$FWDIR/pyspark pyspark/context.py
FAILED=$(($?||$FAILED))

$FWDIR/pyspark -m doctest pyspark/broadcast.py
FAILED=$(($?||$FAILED))

$FWDIR/pyspark -m doctest pyspark/accumulators.py
FAILED=$(($?||$FAILED))

$FWDIR/pyspark -m unittest pyspark.tests
FAILED=$(($?||$FAILED))

if [[ $FAILED != 0 ]]; then
    echo -en "\033[31m"  # Red
    echo "Had test failures; see logs."
    echo -en "\033[0m"  # No color
    exit -1
else
    echo -en "\033[32m"  # Green
    echo "Tests passed."
    echo -en "\033[0m"  # No color
fi

# TODO: in the long-run, it would be nice to use a test runner like `nose`.
# The doctest fixtures are the current barrier to doing this.
